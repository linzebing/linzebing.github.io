---
layout: post
title:  "读《Spark SQL内核剖析》"
date:   2020-08-16 21:03:36 +0530
---

Unresolved LogicalPlan -> Analyzed LogicalPlan -> Optimized LogicalPlan -> Iterator[PhysicalPlan] -> SparkPlan -> Prepared SparkPlan

## Spark SQL执行全过程
InternalRow用来表示一行行数据的类。
- BaseGenericRow 抽象类，实现了InternalRow中定义的所有get类型方法
- JoinedRow 两个InternalRow放在一起形成新的InternalRow
- UnsafeRow 不用Java对象存储方式，避免GC

TreeNode类是Spark SQL中所有树的基类，定义了一系列通用的集合操作和树便利操作接口。树的修改都是以替换已有节点的方式进行的:
- collectLeaves
- collectFirst 先序遍历所有节点并返回第一个满足条件的节点
- withNewChildren
- transformDown 用先序遍历方式规则作用于所有节点
- transformUp 用后序遍历方式将规则作用于所有节点
- transformChildren 递归地将规则作用到所有子节点

Expression
- foldable 用来标记表达式能否在查询执行之前直接静态计算。1. 该表达式为Literal 2. 子表达式foldable均为true
- deterministic 每次eval的输出是否都相同
- nullable 标记表达式是否可能输出Null值，一般在生成的Java代码中对相关条件进行判断
- references 返回AttributeSet类型，表示该Expression中会涉及的属性值，默认情况为所有子节点中属性值的集合
- canonicalized 规范化后的表达式，去除Expr Id等等
- semanticEquals 判断语义上是否等价

![](/assets/pictures/spark-sql/expression.png)

## Spark SQL逻辑计划
字符串形态的SQL语句转换为树形态的逻辑算子树，SQL中所包含的各种处理逻辑（过滤、剪裁等）和数据信息都会被整合在逻辑算子树的不同节点中。本质是一种中间过程表示，与Spark平台无关，后续阶段会被进一步映射为可执行的物理计划。

![](/assets/pictures/spark-sql/logicalplan.png)

### QueryPlan概述
- 输入输出： QueryPlan
- 基本属性：
- 字符串

### Catalog体系分析
Spark SQL系统中，Catalog主要用于各种函数资源信息和元数据信息的统一管理。
